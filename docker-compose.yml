services:
  # ==========================================
  # CPU Version (Default)
  # ==========================================
  ai-judge-cpu:
    build:
      context: .
      dockerfile: docker/Dockerfile.cpu
    image: ai-interview-judge:cpu
    container_name: ai-judge-cpu
    ports:
      - "8000:8000"
    env_file:
      - .env
    volumes:
      # Persistent storage for uploaded files
      - ./temp_uploads:/app/temp_uploads
      - ./temp_audio:/app/temp_audio
      - ./data:/app/data
      - ./logs:/app/logs
    restart: unless-stopped
    healthcheck:
      test: ["CMD", "curl", "-f", "http://localhost:8000/health"]
      interval: 30s
      timeout: 10s
      retries: 3
      start_period: 40s
    networks:
      - ai-judge-network

  # ==========================================
  # GPU Version (NVIDIA)
  # ==========================================
  ai-judge-gpu:
    build:
      context: .
      dockerfile: docker/Dockerfile.gpu
    image: ai-interview-judge:gpu
    container_name: ai-judge-gpu
    ports:
      - "8000:8000"
    env_file:
      - .env
    volumes:
      # Persistent storage for uploaded files
      - ./temp_uploads:/app/temp_uploads
      - ./temp_audio:/app/temp_audio
      - ./data:/app/data
      - ./logs:/app/logs
    restart: unless-stopped
    deploy:
      resources:
        reservations:
          devices:
            - driver: nvidia
              count: 1
              capabilities: [gpu]
    healthcheck:
      test: ["CMD", "curl", "-f", "http://localhost:8000/health"]
      interval: 30s
      timeout: 10s
      retries: 3
      start_period: 40s
    networks:
      - ai-judge-network
    profiles:
      - gpu

  # ==========================================
  # Frontend (Streamlit)
  # ==========================================
  frontend:
    build:
      context: ./frontend
      dockerfile: Dockerfile
    image: ai-interview-judge:frontend
    container_name: ai-judge-frontend
    ports:
      - "8501:8501"  # Доступ из браузера: http://localhost:8501
    environment:
      # Внутри Docker сети фронт должен стучаться к бэкенду по имени сервиса!
      # Если ты запускаешь GPU версию, поменяй тут на http://ai-judge-gpu:8000
      - API_URL=http://ai-judge-cpu:8000
    depends_on:
      ai-judge-cpu:
        condition: service_healthy
    restart: unless-stopped
    networks:
      - ai-judge-network

  # ==========================================
  # Frontend для GPU (Streamlit)
  # ==========================================
  frontend-gpu:
    build:
      context: ./frontend
      dockerfile: Dockerfile
    image: ai-interview-judge:frontend
    container_name: ai-judge-frontend-gpu
    ports:
      - "8501:8501"
    environment:
      - API_URL=http://ai-judge-gpu:8000
    depends_on:
      ai-judge-gpu:
        condition: service_healthy
    restart: unless-stopped
    networks:
      - ai-judge-network
    profiles:
      - gpu

networks:
  ai-judge-network:
    driver: bridge
